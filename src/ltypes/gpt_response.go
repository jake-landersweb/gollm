package ltypes

type GPTCompletionResponse struct {
	// A unique identifier for the chat completion.
	ID string `json:"id"`

	// The object type, which is always chat.completion.
	Object string `json:"object"`

	// The Unix timestamp (in seconds) of when the chat completion was created.
	Created int `json:"created"`

	// The model used for the chat completion.
	Model string `json:"model"`

	// This fingerprint represents the backend configuration that the model runs with.
	// Can be used in conjunction with the seed request parameter to understand when backend changes have been made that might impact determinism.
	SystemFingerprint string `json:"system_fingerprint"`

	// A list of chat completion choices. Can be more than one if n is greater than 1.
	Choices []GPTChoice `json:"choices"`

	//Usage statistics for the completion request.
	Usage GPTUsage `json:"usage"`

	// error information. Will be null if no error exists
	Error *GPTError `json:"error"`
}

type GPTChoice struct {
	// The index of the choice in the list of choices.
	Index int `json:"index"`

	// A chat completion message generated by the model.
	Message GPTCompletionMessage `json:"message"`

	// Log probability information for the choice.
	Logprobs interface{} `json:"logprobs"`

	// The reason the model stopped generating tokens. This will be stop if the model hit a natural stop point or a provided stop sequence, length if the maximum number of tokens specified in the request was reached, content_filter if content was omitted due to a flag from our content filters, tool_calls if the model called a tool, or function_call (deprecated) if the model called a function.
	FinishReason string `json:"finish_reason"`
}

type GPTUsage struct {
	// Number of tokens in the generated completion.
	PromptTokens int `json:"prompt_tokens"`

	// Number of tokens in the prompt.
	CompletionTokens int `json:"completion_tokens"`

	// Total number of tokens used in the request (prompt + completion).
	TotalTokens int `json:"total_tokens"`
}

type GPT_ERROR_TYPE string

const (
	GPT_ERROR_INVALID      GPT_ERROR_TYPE = "invalid_request_error"
	GPT_ERROR_RATE_LIMIT   GPT_ERROR_TYPE = "rate_limit_error"
	GPT_ERROR_TOKENS_LIMIT GPT_ERROR_TYPE = "tokens_exceeded_error"
	GPT_ERROR_AUTH         GPT_ERROR_TYPE = "authentication_error"
	GPT_ERROR_NOT_FOUND    GPT_ERROR_TYPE = "not_found_error"
	GPT_ERROR_SERVER       GPT_ERROR_TYPE = "server_error"
	GPT_ERROR_PERMISSION   GPT_ERROR_TYPE = "permission_error"
)

type GPTError struct {
	Message string         `json:"message"`
	Type    GPT_ERROR_TYPE `json:"type"`
	Param   string         `json:"param"`
	Code    int            `json:"code"`
}
